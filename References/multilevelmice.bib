@article{audigierComparisonMultipleImputation,
  title = {Comparison of Multiple Imputation Methods for Systematically and Sporadically Missing Multilevel Data},
  author = {Audigier, V and White, I and Jolani, S and Debray, T and Quartagno, M and Carpenter, J},
  pages = {20},
  langid = {english},
  file = {C\:\\Users\\4216318\\Zotero\\storage\\5MSGXJYY\\Audigier et al. - Comparison of multiple imputation methods for syst.pdf}
}

@misc{broom.mixed,
  title = {Broom.Mixed: {{Tidying Methods}} for {{Mixed Models}}},
  shorttitle = {Broom.Mixed},
  author = {Bolker [aut, Ben and {cre} and Robinson, David and Menne, Dieter and Gabry, Jonah and Buerkner, Paul and Hua, Christopher and Petry, William and Wiley, Joshua and Kennedy, Patrick and SE), Eduard Sz{\"o}cs (BASF and Patil, Indrajeet and {Arel-Bundock}, Vincent},
  year = {2021},
  month = jul,
  abstract = {Convert fitted objects from various R mixed-model packages into tidy data frames along the lines of the 'broom' package. The package provides three S3 generics for each model: tidy(), which summarizes a model's statistical findings such as coefficients of a regression; augment(), which adds columns to the original data such as predictions, residuals and cluster assignments; and glance(), which provides a one-row summary of model-level statistics.},
  copyright = {GPL-3}
}

@book{buur18,
  title = {Flexible Imputation of Missing Data},
  author = {Van Buuren, Stef},
  year = {2018},
  publisher = {{Chapman and Hall/CRC}}
}

@article{carpenterIntroductionHandlingMissing,
  title = {Introduction to Handling Missing Data in Multilevel Modelling},
  author = {Carpenter, James R},
  langid = {english},
  file = {C\:\\Users\\4216318\\Zotero\\storage\\K3PJ8HW5\\Carpenter - Introduction to handling missing data in multileve.pdf}
}

@article{carpenterMissingDataStatistical2021,
  title = {Missing Data: {{A}} Statistical Framework for Practice},
  shorttitle = {Missing Data},
  author = {Carpenter, James R. and Smuk, Melanie},
  year = {2021},
  journal = {Biometrical Journal},
  volume = {63},
  number = {5},
  pages = {915--947},
  issn = {1521-4036},
  doi = {10.1002/bimj.202000196},
  abstract = {Missing data are ubiquitous in medical research, yet there is still uncertainty over when restricting to the complete records is likely to be acceptable, when more complex methods (e.g. maximum likelihood, multiple imputation and Bayesian methods) should be used, how they relate to each other and the role of sensitivity analysis. This article seeks to address both applied practitioners and researchers interested in a more formal explanation of some of the results. For practitioners, the framework, illustrative examples and code should equip them with a practical approach to address the issues raised by missing data (particularly using multiple imputation), alongside an overview of how the various approaches in the literature relate. In particular, we describe how multiple imputation can be readily used for sensitivity analyses, which are still infrequently performed. For those interested in more formal derivations, we give outline arguments for key results, use simple examples to show how methods relate, and references for full details. The ideas are illustrated with a cohort study, a multi-centre case control study and a randomised clinical trial.},
  langid = {english},
  keywords = {complete records,missing data,multiple imputation,sensitivity analysis},
  file = {C\:\\Users\\4216318\\Zotero\\storage\\4BLZVCE8\\Carpenter and Smuk - 2021 - Missing data A statistical framework for practice.pdf;C\:\\Users\\4216318\\Zotero\\storage\\4XIN4D7M\\bimj.html}
}

@incollection{debr21,
  title = {Dealing with {{Missing Data}} in an {{IPD Meta-Analysis}}},
  booktitle = {Individual {{Participant Data Meta-Analysis}}},
  author = {Debray, Thomas P.A. and Snell, Kym I.E. and Quartagno, Matteo and Jolani, Shahab and Moons, Karel G.M. and Riley, Richard D.},
  year = {2021},
  pages = {499--524},
  publisher = {{John Wiley \& Sons, Ltd}},
  doi = {10.1002/9781119333784.ch18},
  abstract = {This chapter provides an overview of different methods for dealing with missing data in an individual participant data (IPD) meta-analysis. It highlights the specific challenges of dealing with missing data in an IPD meta-analysis context, including how to preserve the clustering of participants within primary studies, whilst allowing for potential between-study heterogeneity. The describes the various types of missing data that can occur in an IPD meta-analysis project, and the strategies, statistical approaches and software to deal with each. It focuses on dealing with missing data in the context of IPD meta-analyses of observational studies, for example for examining prognostic factors or developing prediction models. A number of prognostic factors (`predictors') are known to be associated with the incidence of preeclampsia; for example, a woman has a higher risk if she had pre-eclampsia in a previous pregnancy, or if there is a family history of pre-eclampsia, diabetes, or renal disease.},
  chapter = {18},
  isbn = {978-1-119-33378-4},
  langid = {english},
  keywords = {individual participant data meta-analysis,missing data,prediction models,pregnancy,prognostic factors,statistical approaches,statistical software},
  file = {C\:\\Users\\4216318\\Zotero\\storage\\RC42CWEQ\\Debray et al. - 2021 - Dealing with Missing Data in an IPD Meta-Analysis.pdf}
}

@article{drec15,
  title = {Multiple {{Imputation}} of {{Multilevel Missing Data}}\textemdash{{Rigor Versus Simplicity}}},
  author = {Drechsler, J{\"o}rg},
  year = {2015},
  month = feb,
  journal = {Journal of Educational and Behavioral Statistics},
  volume = {40},
  number = {1},
  pages = {69--95},
  publisher = {{American Educational Research Association}},
  issn = {1076-9986},
  doi = {10.3102/1076998614563393},
  abstract = {Multiple imputation is widely accepted as the method of choice to address item-nonresponse in surveys. However, research on imputation strategies for the hierarchical structures that are typically found in the data in educational contexts is still limited. While a multilevel imputation model should be preferred from a theoretical point of view if the analysis model of interest is also a multilevel model, many practitioners prefer a fixed effects imputation model with dummies for the clusters since these models are easy to set up with standard imputation software. In this article, we theoretically and empirically evaluate the impacts of this simplified approach. We illustrate that the cluster effects that are often of central interest in educational research can be biased if a fixed effects imputation model is used. We show that the potential bias depends on three quantities: the amount of missingness, the intraclass correlation, and the cluster size. We argue that the bias for the random effects can be substantial while the bias for the fixed effects will be negligible in most real-data situations. We further illustrate this with an application using data from the German National Educational Panel Survey.},
  langid = {english},
  keywords = {fixed effects,Imputation,missing data,multilevel,random effects},
  file = {C\:\\Users\\4216318\\Zotero\\storage\\43FF8YT6\\Drechsler - 2015 - Multiple Imputation of Multilevel Missing Data—Rig.pdf}
}

@article{ende16,
  title = {Multilevel Multiple Imputation: {{A}} Review and Evaluation of Joint Modeling and Chained Equations Imputation},
  shorttitle = {Multilevel Multiple Imputation},
  author = {Enders, Craig K. and Mistler, Stephen A. and Keller, Brian T.},
  year = {2016},
  month = jun,
  journal = {Psychological Methods},
  volume = {21},
  number = {2},
  pages = {222--240},
  issn = {1939-1463},
  doi = {10.1037/met0000063},
  abstract = {Although missing data methods have advanced in recent years, methodologists have devoted less attention to multilevel data structures where observations at level-1 are nested within higher-order organizational units at level-2 (e.g., individuals within neighborhoods; repeated measures nested within individuals; students nested within classrooms). Joint modeling and chained equations imputation are the principal imputation frameworks for single-level data, and both have multilevel counterparts. These approaches differ algorithmically and in their functionality; both are appropriate for simple random intercept analyses with normally distributed data, but they differ beyond that. The purpose of this paper is to describe multilevel imputation strategies and evaluate their performance in a variety of common analysis models. Using multiple imputation theory and computer simulations, we derive 4 major conclusions: (a) joint modeling and chained equations imputation are appropriate for random intercept analyses; (b) the joint model is superior for analyses that posit different within- and between-cluster associations (e.g., a multilevel regression model that includes a level-1 predictor and its cluster means, a multilevel structural equation model with different path values at level-1 and level-2); (c) chained equations imputation provides a dramatic improvement over joint modeling in random slope analyses; and (d) a latent variable formulation for categorical variables is quite effective. We use a real data analysis to demonstrate multilevel imputation, and we suggest a number of avenues for future research. (PsycINFO Database Record},
  langid = {english},
  pmid = {26690775},
  keywords = {Computer Simulation,Humans,Multilevel Analysis,Research Design}
}

@article{ende18,
  title = {A Fully Conditional Specification Approach to Multilevel Imputation of Categorical and Continuous Variables.},
  author = {Enders, Craig K. and Keller, Brian T. and Levy, Roy},
  year = {2018},
  month = jun,
  journal = {Psychological Methods},
  volume = {23},
  number = {2},
  pages = {298--317},
  issn = {1939-1463, 1082-989X},
  doi = {10.1037/met0000148},
  abstract = {Specialized imputation routines for multilevel data are widely available in software packages, but these methods are generally not equipped to handle a wide range of complexities that are typical of behavioral science data. In particular, existing imputation schemes differ in their ability to handle random slopes, categorical variables, differential relations at level-1 and level-2, and incomplete level-2 variables. Given the limitations of existing imputation tools, the purpose of this manuscript is to describe a flexible imputation approach that can accommodate a diverse set of two-level analysis problems that includes any of the aforementioned features. The procedure employs a fully conditional specification (also known as chained equations) approach with a latent variable formulation for handling incomplete categorical variables. Computer simulations suggest that the proposed procedure works quite well, with trivial biases in most cases. We provide a software program that implements the imputation strategy, and we use an artificial data set to illustrate its use.},
  langid = {english},
  pmid = {28557466},
  keywords = {Behavioral Research,Data Interpretation; Statistical,Humans,Models; Statistical,Multilevel Analysis},
  file = {C\:\\Users\\4216318\\Zotero\\storage\\J2H75436\\enders-keller--levy-2017--.pdf;C\:\\Users\\4216318\\Zotero\\storage\\UZF2RUXL\\Enders et al. - 2018 - A fully conditional specification approach to mult.pdf}
}

@incollection{fish25,
  title = {Statistical {{Methods}} for {{Research Workers}}},
  booktitle = {Breakthroughs in {{Statistics}}: {{Methodology}} and {{Distribution}}},
  author = {Fisher, R. A.},
  editor = {Kotz, Samuel and Johnson, Norman L.},
  year = {1925},
  series = {Springer {{Series}} in {{Statistics}}},
  pages = {66--70},
  publisher = {{Springer}},
  address = {{New York, NY}},
  doi = {10.1007/978-1-4612-4380-9_6},
  abstract = {The prime object of this book is to put into the hands of research workers, and especially of biologists, the means of applying statistical tests accurately to numerical data accumulated in their own laboratories or available in the literature.},
  isbn = {978-1-4612-4380-9},
  langid = {english},
  keywords = {Manure Plot,Manurial Response,Manurial Treatment,Rothamsted Experimental Station,Total Yield},
  file = {C\:\\Users\\4216318\\Zotero\\storage\\U7WZCBAX\\Statistical_Methods_for_Research_Workers.pdf}
}

@misc{FullArticleImputation,
  title = {Full Article: {{Imputation}} of {{Mixed Data With Multilevel Singular Value Decomposition}}},
  howpublished = {https://www-tandfonline-com.proxy.library.uu.nl/doi/full/10.1080/10618600.2019.1585261}
}

@misc{FullArticleImputationa,
  title = {Full Article: {{Imputation}} of {{Mixed Data With Multilevel Singular Value Decomposition}}},
  howpublished = {https://www-tandfonline-com.proxy.library.uu.nl/doi/full/10.1080/10618600.2019.1585261},
  file = {C\:\\Users\\4216318\\Zotero\\storage\\HZW8443Q\\10618600.2019.html}
}

@book{gelm06,
  title = {Data {{Analysis Using Regression}} and {{Multilevel}}/{{Hierarchical Models}}},
  author = {Gelman, Andrew and Hill, Jennifer},
  year = {2006},
  month = dec,
  publisher = {{Cambridge University Press}},
  abstract = {Data Analysis Using Regression and Multilevel/Hierarchical Models, first published in 2007, is a comprehensive manual for the applied researcher who wants to perform data analysis using linear and nonlinear regression and multilevel models. The book introduces a wide variety of models, whilst at the same time instructing the reader in how to fit these models using available software packages. The book illustrates the concepts by working through scores of real data examples that have arisen from the authors' own applied research, with programming codes provided for each one. Topics covered include causal inference, including regression, poststratification, matching, regression discontinuity, and instrumental variables, as well as multilevel logistic regression and missing-data imputation. Practical tips regarding building, fitting, and understanding are provided throughout.},
  googlebooks = {c9xLKzZWoZ4C},
  isbn = {978-1-139-46093-4},
  langid = {english},
  keywords = {Mathematics / Probability \& Statistics / General,Political Science / General,Psychology / Assessment; Testing \& Measurement,Social Science / Research}
}

@misc{GJRM,
  title = {{{GJRM}}: {{Generalised Joint Regression Modelling}}},
  shorttitle = {{{GJRM}}},
  author = {Radice, Giampiero Marra {and} Rosalba},
  year = {2021},
  month = oct,
  abstract = {Routines for fitting various joint (and univariate) regression models, with several types of covariate effects, in the presence of equations' errors association, endogeneity, non-random sample selection or partial observability.},
  copyright = {GPL-2 | GPL-3 [expanded from: GPL ({$\geq$} 2)]}
}

@article{grun18,
  ids = {grundMultipleImputationMissing2018},
  title = {Multiple {{Imputation}} of {{Missing Data}} for {{Multilevel Models}}: {{Simulations}} and {{Recommendations}}},
  shorttitle = {Multiple {{Imputation}} of {{Missing Data}} for {{Multilevel Models}}},
  author = {Grund, Simon and L{\"u}dtke, Oliver and Robitzsch, Alexander},
  year = {2018},
  month = jan,
  journal = {Organizational Research Methods},
  volume = {21},
  number = {1},
  pages = {111--149},
  publisher = {{SAGE Publications Inc}},
  issn = {1094-4281},
  doi = {10.1177/1094428117703686},
  abstract = {Multiple imputation (MI) is one of the principled methods for dealing with missing data. In addition, multilevel models have become a standard tool for analyzing the nested data structures that result when lower level units (e.g., employees) are nested within higher level collectives (e.g., work groups). When applying MI to multilevel data, it is important that the imputation model takes the multilevel structure into account. In the present paper, based on theoretical arguments and computer simulations, we provide guidance using MI in the context of several classes of multilevel models, including models with random intercepts, random slopes, cross-level interactions (CLIs), and missing data in categorical and group-level variables. Our findings suggest that, oftentimes, several approaches to MI provide an effective treatment of missing data in multilevel research. Yet we also note that the current implementations of MI still have room for improvement when handling missing data in explanatory variables in models with random slopes and CLIs. We identify areas for future research and provide recommendations for research practice along with a number of step-by-step examples for the statistical software R.},
  langid = {english},
  keywords = {cross-level interactions,missing data,multilevel,multiple imputation,random coefficients model,random intercept model,random slopes},
  file = {C\:\\Users\\4216318\\Zotero\\storage\\NXB66H9V\\Grund et al. - 2018 - Multiple Imputation of Missing Data for Multilevel.pdf;C\:\\Users\\4216318\\Zotero\\storage\\UAKLMXHA\\Grund et al. - 2018 - Multiple Imputation of Missing Data for Multilevel.pdf}
}

@incollection{grundMissingDataMultilevel2019,
  title = {Missing Data in Multilevel Research.},
  booktitle = {The Handbook of Multilevel Theory, Measurement, and Analysis.},
  author = {Grund, Simon and L{\"u}dtke, Oliver and Robitzsch, Alexander},
  editor = {Humphrey, Stephen E. and LeBreton, James M.},
  year = {2019},
  pages = {365--386},
  publisher = {{American Psychological Association}},
  address = {{Washington}},
  doi = {10.1037/0000115-017},
  isbn = {978-1-4338-3001-3 978-1-4338-3009-9},
  langid = {english},
  file = {C\:\\Users\\4216318\\Zotero\\storage\\P2TUL9UW\\Grund et al. - 2019 - Missing data in multilevel research..pdf}
}

@article{hammonMultipleImputationBinary2020a,
  title = {Multiple Imputation of Binary Multilevel Missing Not at Random Data},
  author = {Hammon, Angelina and Zinn, Sabine},
  year = {2020},
  month = jun,
  journal = {Journal of the Royal Statistical Society: Series C (Applied Statistics)},
  volume = {69},
  number = {3},
  pages = {547--564},
  issn = {0035-9254, 1467-9876},
  doi = {10.1111/rssc.12401},
  langid = {english},
  file = {C\:\\Users\\4216318\\Zotero\\storage\\4PEVFLX5\\Hammon and Zinn - 2020 - Multiple imputation of binary multilevel missing n.pdf}
}

@article{hammonMultipleImputationOrdinal2022,
  title = {Multiple Imputation of Ordinal Missing Not at Random Data},
  author = {Hammon, Angelina},
  year = {2022},
  month = aug,
  journal = {AStA Advances in Statistical Analysis},
  issn = {1863-818X},
  doi = {10.1007/s10182-022-00461-9},
  abstract = {We introduce a selection model-based imputation approach to be used within the Fully Conditional Specification (FCS) framework for the Multiple Imputation (MI) of incomplete ordinal variables that are supposed to be Missing Not at Random (MNAR). Thereby, we generalise previous work on this topic which involved binary single-level and multilevel data to ordinal variables. We apply an ordered probit model with sample selection as base of our imputation algorithm. The applied model involves two equations that are modelled jointly where the first one describes the missing-data mechanism and the second one specifies the variable to be imputed. In addition, we develop a version for hierarchical data by incorporating random intercept terms in both equations. To fit this multilevel imputation model we use quadrature techniques. Two simulation studies validate the overall good performance of our single-level and multilevel imputation methods. In addition, we show its applicability to empirical data by applying it to a common research topic in educational science using data of the National Educational Panel Study (NEPS) and conducting a short sensitivity analysis. Our approach is designed to be used within the R software package mice which makes it easy to access and apply.},
  langid = {english},
  keywords = {Fully conditional specification,Missingness not at random,Multilevel data,Multiple imputation,Ordinal data,Selection model},
  file = {C\:\\Users\\4216318\\Zotero\\storage\\TWF7EVMG\\Hammon - 2022 - Multiple imputation of ordinal missing not at rand.pdf}
}

@book{heymansandeekhoutChapter7MultipleImputation2019,
  title = {Chapter7 {{Multiple Imputation}} Models for {{Multilevel}} Data | {{Book}}\_{{MI}}.Knit},
  author = {{Heymans {and} Eekhout}},
  year = {2019},
  file = {C\:\\Users\\4216318\\Zotero\\storage\\TZ3B5TFE\\multiple-imputation-models-for-multilevel-data.html}
}

@misc{HomePageBook,
  title = {Home Page for the Book, "{{Applied Regression}} and {{Multilevel Models}}"},
  howpublished = {http://stat.columbia.edu/\textasciitilde gelman/armm/},
  file = {C\:\\Users\\4216318\\Zotero\\storage\\RQ89D3HQ\\armm.html}
}

@incollection{hox15,
  title = {Incomplete {{Multilevel Data}}: {{Problems}} and Solutions},
  shorttitle = {Incomplete {{Multilevel Data}}},
  booktitle = {Advances in Multilevel Modeling for Educational Research: Addressing Practical Issues Found in Real-World Applications},
  author = {Hox, J. and {van Buuren}, S. and Jolani, Shahab},
  editor = {Harring, J.R. and Staplecton, L.M. and Beretvas, S.N.},
  year = {2015},
  series = {{{CILVR Series}} on {{Latent Variable Methodology}}},
  pages = {39--62},
  publisher = {{Information Age Publishing Inc.}},
  address = {{Charlotte, NC}},
  isbn = {978-1-68123-328-4}
}

@book{hox17,
  title = {Multilevel {{Analysis}}: {{Techniques}} and {{Applications}}, {{Third Edition}}},
  shorttitle = {Multilevel {{Analysis}}},
  author = {Hox, Joop J. and Moerbeek, Mirjam and van de Schoot, Rens},
  year = {2017},
  month = sep,
  publisher = {{Routledge}},
  abstract = {Applauded for its clarity, this accessible introduction helps readers apply multilevel techniques to their research. The book also includes advanced extensions, making it useful as both an introduction for students and as a reference for researchers. Basic models and examples are discussed in nontechnical terms with an emphasis on understanding the methodological and statistical issues involved in using these models. The estimation and interpretation of multilevel models is demonstrated using realistic examples from various disciplines including psychology, education, public health, and sociology. Readers are introduced to a general framework on multilevel modeling which covers both observed and latent variables in the same model, while most other books focus on observed variables. In addition, Bayesian estimation is introduced and applied using accessible software.},
  googlebooks = {iLD\_DwAAQBAJ},
  isbn = {978-1-317-30868-3},
  langid = {english},
  keywords = {Education / Statistics,Psychology / Statistics,Social Science / Statistics},
  file = {C\:\\Users\\4216318\\Zotero\\storage\\AKYJ9KVK\\DataStories.pdf;C\:\\Users\\4216318\\Zotero\\storage\\TR27IWUE\\Hox et al. - 2017 - Multilevel Analysis Techniques and Applications, .pdf;C\:\\Users\\4216318\\Zotero\\storage\\YB4GQHGA\\Multilevel Analysis Techniques and Applications by Joop J. Hox, Mirjam Moerbeek, Rens Van De Schoot (z-lib.org).pdf}
}

@book{hoxMultilevelAnalysisTechniques2002,
  title = {Multilevel Analysis: Techniques and Applications},
  shorttitle = {Multilevel Analysis},
  author = {Hox, J. J.},
  year = {2002},
  series = {Quantitative Methodology Series},
  publisher = {{Lawrence Erlbaum Associates}},
  address = {{Mahwah, N.J}},
  isbn = {978-0-8058-3218-1 978-0-8058-3219-8},
  langid = {english},
  lccn = {HA29 .H783 2002},
  keywords = {Analysis of variance,Regression analysis,Social sciences,Statistical methods},
  file = {C\:\\Users\\4216318\\Zotero\\storage\\8DGQZVLI\\Hox - 2002 - Multilevel analysis techniques and applications.pdf}
}

@misc{IndividualParticipantData,
  title = {Individual {{Participant Data Meta-Analysis}}: {{A Handbook}} for {{Healthcare Research}} | {{Wiley}}},
  shorttitle = {Individual {{Participant Data Meta-Analysis}}},
  journal = {Wiley.com},
  abstract = {Individual Participant Data Meta-Analysis: A Handbook for Healthcare Research provides a comprehensive introduction to the fundamental principles and methods that healthcare researchers need when considering, conducting or using individual participant data (IPD) meta-analysis projects. Written and edited by researchers with substantial experience in the field, the book details key concepts and practical guidance for each stage of an IPD meta-analysis project, alongside illustrated examples and summary learning points. Split into five parts, the book chapters take the reader through the journey from initiating and planning IPD projects to obtaining, checking, and meta-analysing IPD, and appraising and reporting findings. The book initially focuses on the synthesis of IPD from randomised trials to evaluate treatment effects, including the evaluation of participant-level effect modifiers (treatment-covariate interactions). Detailed extension is then made to specialist topics such as diagnostic test accuracy, prognostic factors, risk prediction models, and advanced statistical topics such as multivariate and network meta-analysis, power calculations, and missing data. Intended for a broad audience, the book will enable the reader to: Understand the advantages of the IPD approach and decide when it is needed over a conventional systematic review Recognise the scope, resources and challenges of IPD meta-analysis projects Appreciate the importance of a multi-disciplinary project team and close collaboration with the original study investigators Understand how to obtain, check, manage and harmonise IPD from multiple studies Examine risk of bias (quality) of IPD and minimise potential biases throughout the project Understand fundamental statistical methods for IPD meta-analysis, including two-stage and one-stage approaches (and their differences), and statistical software to implement them Clearly report and disseminate IPD meta-analyses to inform policy, practice and future research Critically appraise existing IPD meta-analysis projects Address specialist topics such as effect modification, multiple correlated outcomes, multiple treatment comparisons, non-linear relationships, test accuracy at multiple thresholds, multiple imputation, and developing and validating clinical prediction models Detailed examples and case studies are provided throughout.},
  howpublished = {https://www.wiley.com/en-gb/Individual+Participant+Data+Meta+Analysis\%3A+A+Handbook+for+Healthcare+Research-p-9781119333753},
  langid = {british},
  file = {C\:\\Users\\4216318\\Zotero\\storage\\ZJFJZBPY\\Individual+Participant+Data+Meta+Analysis+A+Handbook+for+Healthcare+Research-p-9781119333753.html}
}

@article{jadhavComparisonPerformanceData2019,
  title = {Comparison of {{Performance}} of {{Data Imputation Methods}} for {{Numeric Dataset}}},
  author = {Jadhav, Anil and Pramod, Dhanya and Ramanathan, Krishnan},
  year = {2019},
  month = aug,
  journal = {Applied Artificial Intelligence},
  volume = {33},
  number = {10},
  pages = {913--933},
  publisher = {{Taylor \& Francis}},
  issn = {0883-9514},
  doi = {10.1080/08839514.2019.1637138},
  abstract = {Missing data is common problem faced by researchers and data scientists. Therefore, it is required to handle them appropriately in order to get better and accurate results of data analysis. Objective of this research paper is to provide better understanding of data missingness mechanism, data imputation methods, and to assess performance of the widely used data imputation methods for numeric dataset. It will help practitioners and data scientists to select appropriate method of data imputation for numeric dataset while performing data mining task. In this paper, we comprehensively compare seven data imputation methods namely mean imputation, median imputation, kNN imputation, predictive mean matching, Bayesian Linear Regression (norm), Linear Regression, non-Bayesian (norm.nob), and random sample. We have used five different numeric datasets obtained from UCI machine learning repository for analyzing and comparing performance of the data imputation methods. Performance of the data imputation methods is assessed using Normalized Root Mean Square Error (RMSE) method. The results of analysis show that kNN imputation method outperforms the other methods. It has also been found that performance of the data imputation method is independent of the dataset and percentage of missing values in the dataset.},
  file = {C\:\\Users\\4216318\\Zotero\\storage\\QIIWRUFF\\Jadhav et al. - 2019 - Comparison of Performance of Data Imputation Metho.pdf;C\:\\Users\\4216318\\Zotero\\storage\\LK5Y6K7L\\08839514.2019.html}
}

@misc{JohamunozHeckmanIPDMAIPDMA,
  title = {Johamunoz/{{Heckman-IPDMA}}: {{IPDMA}} Imputation via {{Heckman}} Models},
  shorttitle = {Johamunoz/{{Heckman-IPDMA}}},
  journal = {GitHub},
  abstract = {IPDMA imputation via Heckman models. Contribute to johamunoz/Heckman-IPDMA development by creating an account on GitHub.},
  howpublished = {https://github.com/johamunoz/Heckman-IPDMA},
  langid = {english},
  file = {C\:\\Users\\4216318\\Zotero\\storage\\P7RQ4VK6\\Heckman-IPDMA.html}
}

@article{jola18,
  title = {Hierarchical Imputation of Systematically and Sporadically Missing Data: {{An}} Approximate {{Bayesian}} Approach Using Chained Equations},
  shorttitle = {Hierarchical Imputation of Systematically and Sporadically Missing Data},
  author = {Jolani, Shahab},
  year = {2018},
  month = mar,
  journal = {Biometrical Journal. Biometrische Zeitschrift},
  volume = {60},
  number = {2},
  pages = {333--351},
  issn = {1521-4036},
  doi = {10.1002/bimj.201600220},
  abstract = {In health and medical sciences, multiple imputation (MI) is now becoming popular to obtain valid inferences in the presence of missing data. However, MI of clustered data such as multicenter studies and individual participant data meta-analysis requires advanced imputation routines that preserve the hierarchical structure of data. In clustered data, a specific challenge is the presence of systematically missing data, when a variable is completely missing in some clusters, and sporadically missing data, when it is partly missing in some clusters. Unfortunately, little is known about how to perform MI when both types of missing data occur simultaneously. We develop a new class of hierarchical imputation approach based on chained equations methodology that simultaneously imputes systematically and sporadically missing data while allowing for arbitrary patterns of missingness among them. Here, we use a random effect imputation model and adopt a simplification over fully Bayesian techniques such as Gibbs sampler to directly obtain draws of parameters within each step of the chained equations. We justify through theoretical arguments and extensive simulation studies that the proposed imputation methodology has good statistical properties in terms of bias and coverage rates of parameter estimates. An illustration is given in a case study with eight individual participant datasets.},
  langid = {english},
  pmid = {28990686},
  keywords = {Bayes Theorem,Biometry,conditional imputation,Female,Glomerular Filtration Rate,Humans,Male,multilevel imputation,multiple imputation by chained equations (MICE),Prognosis,Renal Insufficiency,sequential regression imputation,Software}
}

@article{jomo,
  title = {Jomo: {{A Flexible Package}} for {{Two-level Joint Modelling Multiple Imputation}}},
  shorttitle = {Jomo},
  author = {Quartagno, Matteo and Grund, Simon and Carpenter, James},
  year = {2019},
  journal = {The R Journal},
  volume = {11},
  number = {2},
  pages = {205--228},
  issn = {2073-4859},
  langid = {english},
  file = {C\:\\Users\\4216318\\Zotero\\storage\\BDNAUWAX\\index.html}
}

@article{jong21,
  ids = {dejongDevelopingMoreGeneralizable2021a},
  title = {Developing More Generalizable Prediction Models from Pooled Studies and Large Clustered Data Sets},
  author = {{de Jong}, Valentijn M. T. and Moons, Karel G. M. and Eijkemans, Marinus J. C. and Riley, Richard D. and Debray, Thomas P. A.},
  year = {2021},
  journal = {Statistics in Medicine},
  volume = {40},
  number = {15},
  pages = {3533--3559},
  issn = {1097-0258},
  doi = {10.1002/sim.8981},
  abstract = {Prediction models often yield inaccurate predictions for new individuals. Large data sets from pooled studies or electronic healthcare records may alleviate this with an increased sample size and variability in sample characteristics. However, existing strategies for prediction model development generally do not account for heterogeneity in predictor-outcome associations between different settings and populations. This limits the generalizability of developed models (even from large, combined, clustered data sets) and necessitates local revisions. We aim to develop methodology for producing prediction models that require less tailoring to different settings and populations. We adopt internal-external cross-validation to assess and reduce heterogeneity in models' predictive performance during the development. We propose a predictor selection algorithm that optimizes the (weighted) average performance while minimizing its variability across the hold-out clusters (or studies). Predictors are added iteratively until the estimated generalizability is optimized. We illustrate this by developing a model for predicting the risk of atrial fibrillation and updating an existing one for diagnosing deep vein thrombosis, using individual participant data from 20 cohorts (N = 10 873) and 11 diagnostic studies (N = 10 014), respectively. Meta-analysis of calibration and discrimination performance in each hold-out cluster shows that trade-offs between average and heterogeneity of performance occurred. Our methodology enables the assessment of heterogeneity of prediction model performance during model development in multiple or clustered data sets, thereby informing researchers on predictor selection to improve the generalizability to different settings and populations, and reduce the need for model tailoring. Our methodology has been implemented in the R package metamisc.},
  langid = {english},
  keywords = {heterogeneity,individual participant data,internal-external cross-validation,prediction},
  file = {C\:\\Users\\4216318\\Zotero\\storage\\636PSCY4\\de Jong et al. - 2021 - Developing more generalizable prediction models fr.pdf;C\:\\Users\\4216318\\Zotero\\storage\\6L6I3Z7F\\de Jong et al. - 2021 - Developing more generalizable prediction models fr.pdf;C\:\\Users\\4216318\\Zotero\\storage\\9IQCUIT7\\sim.html}
}

@misc{lme4,
  title = {Lme4: {{Linear Mixed-Effects Models}} Using '{{Eigen}}' and {{S4}}},
  shorttitle = {Lme4},
  author = {Bates, Douglas and Maechler, Martin and Bolker [aut, Ben and {cre} and Walker, Steven and Christensen, Rune Haubo Bojesen and Singmann, Henrik and Dai, Bin and Scheipl, Fabian and Grothendieck, Gabor and Green, Peter and Fox, John and Bauer, Alexander and copyright on {simulate.formula)}, Pavel N. Krivitsky (shared},
  year = {2022},
  month = feb,
  abstract = {Fit linear and generalized linear mixed-effects models. The models and their components are represented using S4 classes and methods. The core computational algorithms are implemented using the 'Eigen' C++ library for numerical linear algebra and 'RcppEigen' "glue".},
  copyright = {GPL-2 | GPL-3 [expanded from: GPL ({$\geq$} 2)]},
  keywords = {Econometrics,Environmetrics,OfficialStatistics,Psychometrics,SocialSciences,SpatioTemporal}
}

@article{loca01,
  title = {Adjustments for Center in Multicenter Studies: An Overview},
  shorttitle = {Adjustments for Center in Multicenter Studies},
  author = {Localio, A. R. and Berlin, J. A. and Ten Have, T. R. and Kimmel, S. E.},
  year = {2001},
  month = jul,
  journal = {Annals of Internal Medicine},
  volume = {135},
  number = {2},
  pages = {112--123},
  issn = {0003-4819},
  doi = {10.7326/0003-4819-135-2-200107170-00012},
  abstract = {Increasingly, investigators rely on multicenter or multigroup studies to demonstrate effectiveness and generalizability. Authors too often overlook the analytic challenges in these study designs: the correlation of outcomes and exposures among patients within centers, confounding of associations by center, and effect modification of treatment or exposure across center. Correlation or clustering, resulting from the similarity of outcomes among patients within a center, requires an adjustment to confidence intervals and P values, especially in observational studies and in randomized multicenter studies in which treatment is allocated by center rather than by individual patient. Multicenter designs also warrant testing and adjustment for the potential bias of confounding by center, and for the presence of effect modification or interaction by center. This paper uses examples from the recent biomedical literature to highlight the issues and analytic options.},
  langid = {english},
  pmid = {11453711},
  keywords = {Bias,Confidence Intervals,Confounding Factors; Epidemiologic,Data Interpretation; Statistical,Humans,Multicenter Studies as Topic,Randomized Controlled Trials as Topic,Research Design}
}

@article{meng94,
  ids = {meng1994multiple},
  title = {Multiple-{{Imputation Inferences}} with {{Uncongenial Sources}} of {{Input}}},
  author = {Meng, Xiao-Li},
  year = {1994},
  month = nov,
  journal = {Statistical Science},
  volume = {9},
  number = {4},
  pages = {538--558},
  publisher = {{JSTOR}},
  issn = {0883-4237, 2168-8745},
  doi = {10.1214/ss/1177010269},
  abstract = {Conducting sample surveys, imputing incomplete observations, and analyzing the resulting data are three indispensable phases of modern practice with public-use data files and with many other statistical applications. Each phase inherits different input, including the information preceding it and the intellectual assessments available, and aims to provide output that is one step closer to arriving at statistical inferences with scientific relevance. However, the role of the imputation phase has often been viewed as merely providing computational convenience for users of data. Although facilitating computation is very important, such a viewpoint ignores the imputer's assessments and information inaccessible to the users. This view underlies the recent controversy over the validity of multiple-imputation inference when a procedure for analyzing multiply imputed data sets cannot be derived from (is "uncongenial" to) the model adopted for multiple imputation. Given sensible imputations and complete-data analysis procedures, inferences from standard multiple-imputation combining rules are typically superior to, and thus different from, users' incomplete-data analyses. The latter may suffer from serious nonresponse biases because such analyses often must rely on convenient but unrealistic assumptions about the nonresponse mechanism. When it is desirable to conduct inferences under models for nonresponse other than the original imputation model, a possible alternative to recreating imputations is to incorporate appropriate importance weights into the standard combining rules. These points are reviewed and explored by simple examples and general theory, from both Bayesian and frequentist perspectives, particularly from the randomization perspective. Some convenient terms are suggested for facilitating communication among researchers from different perspectives when evaluating multiple-imputation inferences with uncongenial sources of input.},
  date-added = {2016-02-04 19:29:48 +0000},
  date-modified = {2016-02-04 23:48:01 +0000},
  langid = {english},
  keywords = {Congeniality,importance sampling,incomplete data,missing data,nonresponse,normalizing constants,public-use data file,randomization,self-efficiency},
  file = {C\:\\Users\\4216318\\Zotero\\storage\\LDSDEUAS\\Meng - 1994 - Multiple-Imputation Inferences with Uncongenial So.pdf;C\:\\Users\\4216318\\Zotero\\storage\\PHA35LD7\\Meng - 1994 - Multiple-Imputation Inferences with Uncongenial So.pdf;C\:\\Users\\4216318\\Zotero\\storage\\MNNUQRPL\\1177010269.html}
}

@misc{metamisc,
  title = {Metamisc: {{Meta-Analysis}} of {{Diagnosis}} and {{Prognosis Research Studies}}},
  shorttitle = {Metamisc},
  author = {Debray, Thomas and de Jong, Valentijn},
  year = {2021},
  month = sep,
  abstract = {Facilitate frequentist and Bayesian meta-analysis of diagnosis and prognosis research studies. It includes functions to summarize multiple estimates of prediction model discrimination and calibration performance (Debray et al., 2019) {$<$}doi:10.1177/0962280218785504{$>$}. It also includes functions to evaluate funnel plot asymmetry (Debray et al., 2018) {$<$}doi:10.1002/jrsm.1266{$>$}. Finally, the package provides functions for developing multivariable prediction models from datasets with clustering (de Jong et al., 2021) {$<$}doi:10.1002/sim.8981{$>$}.},
  copyright = {GPL-3},
  keywords = {MetaAnalysis}
}

@misc{mice,
  title = {Mice: {{Multivariate Imputation}} by {{Chained Equations}}},
  shorttitle = {Mice},
  author = {van Buuren, Stef and {Groothuis-Oudshoorn}, Karin},
  year = {2021},
  month = nov,
  abstract = {Multiple imputation using Fully Conditional Specification (FCS) implemented by the MICE algorithm as described in Van Buuren and Groothuis-Oudshoorn (2011) {$<$}doi:10.18637/jss.v045.i03{$>$}. Each variable has its own imputation model. Built-in imputation models are provided for continuous data (predictive mean matching, normal), binary data (logistic regression), unordered categorical data (polytomous logistic regression) and ordered categorical data (proportional odds). MICE can also impute continuous two-level data (normal model, pan, second-level variables). Passive imputation can be used to maintain consistency between variables. Various diagnostic plots are available to inspect the quality of the imputations.},
  collaborator = {Vink, Gerko and Schouten, Rianne and Robitzsch, Alexander and Rockenschaub, Patrick and Doove, Lisa and Jolani, Shahab and {Moreno-Betancur}, Margarita and White, Ian and Gaffert, Philipp and Meinfelder, Florian and Gray, Bernie and {Arel-Bundock}, Vincent and Cai, Mingyang and Volker, Thom and Costantini, Edoardo and van Lissa, Caspar},
  copyright = {GPL-2 | GPL-3},
  keywords = {MissingData,Multivariate,OfficialStatistics,SocialSciences}
}

@misc{miceadds,
  title = {Miceadds: {{Some Additional Multiple Imputation Functions}}, {{Especially}} for 'Mice'},
  shorttitle = {Miceadds},
  author = {{Robitzsch ({$<$}https://orcid.org/0000-0002-8226-3132{$>$})}, Alexander and {Grund ({$<$}https://orcid.org/0000-0002-1290-8986{$>$})}, Simon and Henke, Thorsten},
  year = {2021},
  month = jan,
  abstract = {Contains functions for multiple imputation which complements existing functionality in R. In particular, several imputation methods for the mice package (van Buuren \& Groothuis-Oudshoorn, 2011, {$<$}doi:10.18637/jss.v045.i03{$>$}) are included. Main features of the miceadds package include plausible value imputation (Mislevy, 1991, {$<$}doi:10.1007/BF02294457{$>$}), multilevel imputation for variables at any level or with any number of hierarchical and non-hierarchical levels (Grund, Luedtke \& Robitzsch, 2018, {$<$}doi:10.1177/1094428117703686{$>$}; van Buuren, 2018, Ch.7, {$<$}doi:10.1201/9780429492259{$>$}), imputation using partial least squares (PLS) for high dimensional predictors (Robitzsch, Pham \& Yanagida, 2016), nested multiple imputation (Rubin, 2003, {$<$}doi:10.1111/1467-9574.00217{$>$}), substantive model compatible imputation (Bartlett et al., 2015, {$<$}doi:10.1177/0962280214521348{$>$}), and features for the generation of synthetic datasets (Reiter, 2005, {$<$}doi:10.1111/j.1467-985X.2004.00343.x{$>$}; Nowok, Raab, \& Dibben, 2016, {$<$}doi:10.18637/jss.v074.i11{$>$}).},
  copyright = {GPL-2 | GPL-3 [expanded from: GPL ({$\geq$} 2)]},
  keywords = {MissingData}
}

@misc{MiceImputingMultilevel,
  title = {Mice: {{Imputing}} Multi-Level Data},
  howpublished = {https://www.gerkovink.com/miceVignettes/Multi\_level/Multi\_level\_data.html},
  file = {C\:\\Users\\4216318\\Zotero\\storage\\TFIT44UF\\Multi_level_data.html}
}

@misc{MissingDataStatistical,
  title = {Missing Data: {{A}} Statistical Framework for Practice - {{PubMed}}},
  howpublished = {https://pubmed.ncbi.nlm.nih.gov/33624862/},
  file = {C\:\\Users\\4216318\\Zotero\\storage\\LS6Q9LJV\\33624862.html}
}

@misc{MissingDataStatisticala,
  title = {Missing Data: {{A}} Statistical Framework for Practice - {{Carpenter}} - 2021 - {{Biometrical Journal}} - {{Wiley Online Library}}},
  howpublished = {https://onlinelibrary.wiley.com/doi/10.1002/bimj.202000196},
  file = {C\:\\Users\\4216318\\Zotero\\storage\\JICRHV67\\bimj.html}
}

@misc{MultipleImputationMissing,
  title = {Multiple {{Imputation}} of {{Missing Data}} for {{Multilevel Models}}: {{Simulations}} and {{Recommendations}} - {{Simon Grund}}, {{Oliver L\"udtke}}, {{Alexander Robitzsch}}, 2018},
  howpublished = {https://journals-sagepub-com.proxy.library.uu.nl/doi/full/10.1177/1094428117703686},
  file = {C\:\\Users\\4216318\\Zotero\\storage\\XJNWPK2P\\1094428117703686.html}
}

@misc{MultipleImputationOrdinal,
  title = {Multiple Imputation of Ordinal Missing Not at Random Data | {{SpringerLink}}},
  howpublished = {https://link.springer.com/article/10.1007/s10182-022-00461-9},
  file = {C\:\\Users\\4216318\\Zotero\\storage\\YLZ546LI\\s10182-022-00461-9.html}
}

@misc{MultipleImputationOrdinala,
  title = {Multiple Imputation of Ordinal Missing Not at Random Data | {{SpringerLink}}},
  howpublished = {https://link.springer.com/article/10.1007/s10182-022-00461-9},
  file = {C\:\\Users\\4216318\\Zotero\\storage\\LTXQB5QE\\s10182-022-00461-9.html}
}

@article{munozDealingMissingData2023,
  title = {Dealing with Missing Data Using the {{Heckman}} Selection Model: Methods Primer for Epidemiologists},
  shorttitle = {Dealing with Missing Data Using the {{Heckman}} Selection Model},
  author = {Mu{\~n}oz, Johanna and Hufstedler, Heather and Gustafson, Paul and B{\"a}rnighausen, Till and De Jong, Valentijn M T and Debray, Thomas P A},
  year = {2023},
  month = jan,
  journal = {International Journal of Epidemiology},
  pages = {dyac237},
  issn = {0300-5771},
  doi = {10.1093/ije/dyac237},
  file = {C\:\\Users\\4216318\\Zotero\\storage\\BUKK769E\\Muñoz et al. - 2023 - Dealing with missing data using the Heckman select.pdf}
}

@article{paananenGroupHeterogeneityAssessment2020,
  title = {Group {{Heterogeneity Assessment}} for {{Multilevel Models}}},
  author = {Paananen, Topi and Catalina, Alejandro and B{\"u}rkner, Paul-Christian and Vehtari, Aki},
  year = {2020},
  month = may,
  journal = {arXiv:2005.02773 [stat]},
  eprint = {2005.02773},
  primaryclass = {stat},
  abstract = {Many data sets contain an inherent multilevel structure, for example, because of repeated measurements of the same observational units. Taking this structure into account is critical for the accuracy and calibration of any statistical analysis performed on such data. However, the large number of possible model configurations hinders the use of multilevel models in practice. In this work, we propose a flexible framework for efficiently assessing differences between the levels of given grouping variables in the data. The assessed group heterogeneity is valuable in choosing the relevant group coefficients to consider in a multilevel model. Our empirical evaluations demonstrate that the framework can reliably identify relevant multilevel components in both simulated and real data sets.},
  archiveprefix = {arxiv},
  keywords = {Statistics - Computation,Statistics - Machine Learning,Statistics - Methodology},
  file = {C\:\\Users\\4216318\\Zotero\\storage\\5D7INZSV\\Paananen et al. - 2020 - Group Heterogeneity Assessment for Multilevel Mode.pdf;C\:\\Users\\4216318\\Zotero\\storage\\9548DHUL\\2005.html}
}

@misc{PracticalsEP16Missing,
  title = {Practicals {$\cdot$} {{EP16}}: {{Missing Values}} in {{Clinical Research}}},
  howpublished = {https://nerler.github.io/EP16\_Multiple\_Imputation/practical/},
  file = {C\:\\Users\\4216318\\Zotero\\storage\\9EDGD8T6\\practical.html}
}

@misc{RandomEffectsLongitudinal,
  ids = {RandomEffectsLongitudinala},
  title = {R - {{Random Effects}} in {{Longitudinal Multilevel Imputation Models Using MICE}}},
  journal = {Stack Overflow},
  howpublished = {https://stackoverflow.com/questions/47950304/random-effects-in-longitudinal-multilevel-imputation-models-using-mice},
  file = {C\:\\Users\\4216318\\Zotero\\storage\\8MQ6X8IA\\random-effects-in-longitudinal-multilevel-imputation-models-using-mice.html}
}

@article{reit06,
  title = {The Importance of Modeling the Sampling Design in Multiple Imputation for Missing Data},
  author = {Reiter, Jerome P. and Raghunathan, T. and Kinney, Satkartar K.},
  year = {2006},
  journal = {undefined},
  abstract = {The~theory of multiple~imputation~for missing data~requires that imputations~be~made~conditional on~the~sampling design. However, most standard software packages for performing model\-based multiple imputation assume simple random samples, leading many practitioners~not to account for complex~sample~design~features, such~as~stratification and~clustering, in~their imputations. Theory predicts~that analyses~of such~multiply\-imputed~data~sets~can~yield~biased~estimates from the design\-based perspective. In~this article, we~illustrate~through~simulation that (i) the~bias~can be severe~when the design features~are~related~to the~survey variables~of interest, and~(ii) the~bias~can~be~reduced~by controlling for the~design~features in~the~imputation~models. The~simulations~also illustrate that conditioning on~irrelevant design~features~in~the~imputation models~can~yield~conservative~inferences, provided~that the~models~include~other relevant predictors. These~results~suggest a prescription~for imputers: the~safest course of action is to include~design~variables~in~the~specification~of imputation~models. Using real data, we demonstrate~a~simple~approach~for incorporating complex~design~features~that can~be~used~with some~of the standard software packages for creating multiple imputations.},
  langid = {english},
  file = {C\:\\Users\\4216318\\Zotero\\storage\\WBJGXGZG\\177eba9480b656452ff4dff51fcd95a629c647c5.html}
}

@article{rubi76,
  ids = {rubin1976inference},
  title = {Inference and {{Missing Data}}},
  author = {Rubin, Donald B.},
  year = {1976},
  journal = {Biometrika},
  volume = {63},
  number = {3},
  pages = {581--592},
  publisher = {{Biometrika Trust}},
  doi = {10.2307/2335739},
  abstract = {When making sampling distribution inferences about the parameter of the data, \texttheta, it is appropriate to ignore the process that causes missing data if the missing data are `missing at random' and the observed data are `observed at random', but these inferences are generally conditional on the observed pattern of missing data. When making direct-likelihood or Bayesian inferences about \texttheta, it is appropriate to ignore the process that causes missing data if the missing data are missing at random and the parameter of the missing data process is `distinct' from \texttheta. These conditions are the weakest general conditions under which ignoring the process that causes missing data always leads to correct inferences.},
  date-added = {2016-01-31 19:05:50 +0000},
  date-modified = {2016-01-31 19:05:50 +0000},
  file = {C\:\\Users\\4216318\\Zotero\\storage\\XIZEI53J\\Rubin - 1976 - Inference and Missing Data.pdf}
}

@book{scha97,
  title = {Analysis of Incomplete Multivariate Data},
  author = {Schafer, Joseph L},
  year = {1997},
  publisher = {{Chapman and Hall/CRC}},
  file = {C\:\\Users\\4216318\\Zotero\\storage\\Q7G6U2VV\\Schafer - 1997 - Analysis of incomplete multivariate data.pdf;C\:\\Users\\4216318\\Zotero\\storage\\VEI29NIR\\Schafer - 1997 - Analysis of incomplete multivariate data.pdf}
}

@misc{sportisseEstimationImputationProbabilistic2020a,
  title = {Estimation and Imputation in {{Probabilistic Principal Component Analysis}} with {{Missing Not At Random}} Data},
  author = {Sportisse, Aude and Boyer, Claire and Josse, Julie},
  year = {2020},
  month = jun,
  number = {arXiv:1906.02493},
  eprint = {arXiv:1906.02493},
  publisher = {{arXiv}},
  doi = {10.48550/arXiv.1906.02493},
  abstract = {Missing Not At Random (MNAR) values lead to significant biases in the data, since the probability of missingness depends on the unobserved values.They are ''not ignorable'' in the sense that they often require defining a model for the missing data mechanism, which makes inference or imputation tasks more complex. Furthermore, this implies a strong \textbackslash textit\{a priori\} on the parametric form of the distribution.However, some works have obtained guarantees on the estimation of parameters in the presence of MNAR data, without specifying the distribution of missing data \textbackslash citep\{mohan2018estimation, tang2003analysis\}. This is very useful in practice, but is limited to simple cases such as self-masked MNAR values in data generated according to linear regression models.We continue this line of research, but extend it to a more general MNAR mechanism, in a more general model of the probabilistic principal component analysis (PPCA), \textbackslash textit\{i.e.\}, a low-rank model with random effects. We prove identifiability of the PPCA parameters. We then propose an estimation of the loading coefficients and a data imputation method. They are based on estimators of means, variances and covariances of missing variables, for which consistency is discussed. These estimators have the great advantage of being calculated using only the observed data, leveraging the underlying low-rank structure of the data. We illustrate the relevance of the method with numerical experiments on synthetic data and also on real data collected from a medical register.},
  archiveprefix = {arxiv},
  keywords = {Mathematics - Statistics Theory},
  file = {C\:\\Users\\4216318\\Zotero\\storage\\ZFDPFXX3\\Sportisse et al. - 2020 - Estimation and imputation in Probabilistic Princip.pdf;C\:\\Users\\4216318\\Zotero\\storage\\9XS7WNS4\\1906.html}
}

@misc{sportisseImputationLowrankEstimation2020a,
  title = {Imputation and Low-Rank Estimation with {{Missing Not At Random}} Data},
  author = {Sportisse, Aude and Boyer, Claire and Josse, Julie},
  year = {2020},
  month = jan,
  number = {arXiv:1812.11409},
  eprint = {arXiv:1812.11409},
  publisher = {{arXiv}},
  doi = {10.48550/arXiv.1812.11409},
  abstract = {Missing values challenge data analysis because many supervised and unsupervised learning methods cannot be applied directly to incomplete data. Matrix completion based on low-rank assumptions are very powerful solution for dealing with missing values. However, existing methods do not consider the case of informative missing values which are widely encountered in practice. This paper proposes matrix completion methods to recover Missing Not At Random (MNAR) data. Our first contribution is to suggest a model-based estimation strategy by modelling the missing mechanism distribution. An EM algorithm is then implemented, involving a Fast Iterative Soft-Thresholding Algorithm (FISTA). Our second contribution is to suggest a computationally efficient surrogate estimation by implicitly taking into account the joint distribution of the data and the missing mechanism: the data matrix is concatenated with the mask coding for the missing values; a low-rank structure for exponential family is assumed on this new matrix, in order to encode links between variables and missing mechanisms. The methodology that has the great advantage of handling different missing value mechanisms is robust to model specification errors.The performances of our methods are assessed on the real data collected from a trauma registry (TraumaBase ) containing clinical information about over twenty thousand severely traumatized patients in France. The aim is then to predict if the doctors should administrate tranexomic acid to patients with traumatic brain injury, that would limit excessive bleeding.},
  archiveprefix = {arxiv},
  keywords = {Computer Science - Machine Learning,Statistics - Machine Learning},
  file = {C\:\\Users\\4216318\\Zotero\\storage\\MQ3CDKH2\\Sportisse et al. - 2020 - Imputation and low-rank estimation with Missing No.pdf;C\:\\Users\\4216318\\Zotero\\storage\\B8N7MPPE\\1812.html}
}

@article{steyerbergAssessmentHeterogeneityIndividual2019,
  title = {Assessment of Heterogeneity in an Individual Participant Data Meta-Analysis of Prediction Models: {{An}} Overview and Illustration},
  shorttitle = {Assessment of Heterogeneity in an Individual Participant Data Meta-Analysis of Prediction Models},
  author = {Steyerberg, Ewout W. and Nieboer, Daan and Debray, Thomas P.A. and {van Houwelingen}, Hans C.},
  year = {2019},
  journal = {Statistics in Medicine},
  volume = {38},
  number = {22},
  pages = {4290--4309},
  issn = {1097-0258},
  doi = {10.1002/sim.8296},
  abstract = {Clinical prediction models aim to provide estimates of absolute risk for a diagnostic or prognostic endpoint. Such models may be derived from data from various studies in the context of a meta-analysis. We describe and propose approaches for assessing heterogeneity in predictor effects and predictions arising from models based on data from different sources. These methods are illustrated in a case study with patients suffering from traumatic brain injury, where we aim to predict 6-month mortality based on individual patient data using meta-analytic techniques (15 studies, n = 11 022 patients). The insights into various aspects of heterogeneity are important to develop better models and understand problems with the transportability of absolute risk predictions.},
  langid = {english},
  keywords = {heterogeneity,meta-analysis,prediction,regression modeling},
  file = {C\:\\Users\\4216318\\Zotero\\storage\\QWK2B4FS\\Steyerberg et al. - 2019 - Assessment of heterogeneity in an individual parti.pdf;C\:\\Users\\4216318\\Zotero\\storage\\ZII3I48Y\\sim.html}
}

@article{steyerbergPredictingOutcomeTraumatic2008,
  title = {Predicting {{Outcome}} after {{Traumatic Brain Injury}}: {{Development}} and {{International Validation}} of {{Prognostic Scores Based}} on {{Admission Characteristics}}},
  shorttitle = {Predicting {{Outcome}} after {{Traumatic Brain Injury}}},
  author = {Steyerberg, Ewout W. and Mushkudiani, Nino and Perel, Pablo and Butcher, Isabella and Lu, Juan and McHugh, Gillian S. and Murray, Gordon D. and Marmarou, Anthony and Roberts, Ian and Habbema, J. Dik F. and Maas, Andrew I. R.},
  year = {2008},
  month = aug,
  journal = {PLOS Medicine},
  volume = {5},
  number = {8},
  pages = {e165},
  publisher = {{Public Library of Science}},
  issn = {1549-1676},
  doi = {10.1371/journal.pmed.0050165},
  abstract = {Background Traumatic brain injury (TBI) is a leading cause of death and disability. A reliable prediction of outcome on admission is of great clinical relevance. We aimed to develop prognostic models with readily available traditional and novel predictors. Methods and Findings Prospectively collected individual patient data were analyzed from 11 studies. We considered predictors available at admission in logistic regression models to predict mortality and unfavorable outcome according to the Glasgow Outcome Scale at 6 mo after injury. Prognostic models were developed in 8,509 patients with severe or moderate TBI, with cross-validation by omission of each of the 11 studies in turn. External validation was on 6,681 patients from the recent Medical Research Council Corticosteroid Randomisation after Significant Head Injury (MRC CRASH) trial. We found that the strongest predictors of outcome were age, motor score, pupillary reactivity, and CT characteristics, including the presence of traumatic subarachnoid hemorrhage. A prognostic model that combined age, motor score, and pupillary reactivity had an area under the receiver operating characteristic curve (AUC) between 0.66 and 0.84 at cross-validation. This performance could be improved (AUC increased by approximately 0.05) by considering CT characteristics, secondary insults (hypotension and hypoxia), and laboratory parameters (glucose and hemoglobin). External validation confirmed that the discriminative ability of the model was adequate (AUC 0.80). Outcomes were systematically worse than predicted, but less so in 1,588 patients who were from high-income countries in the CRASH trial. Conclusions Prognostic models using baseline characteristics provide adequate discrimination between patients with good and poor 6 mo outcomes after TBI, especially if CT and laboratory findings are considered in addition to traditional predictors. The model predictions may support clinical practice and research, including the design and analysis of randomized controlled trials.},
  langid = {english},
  keywords = {Computed axial tomography,Glucose,Head injury,Hypotension,Hypoxia,Motor reactions,Randomized controlled trials,Traumatic brain injury},
  file = {C\:\\Users\\4216318\\Zotero\\storage\\RGTS936N\\Steyerberg et al. - 2008 - Predicting Outcome after Traumatic Brain Injury D.pdf;C\:\\Users\\4216318\\Zotero\\storage\\268TR3WY\\article.html}
}

@article{steyerbergPredictingOutcomeTraumatic2008a,
  title = {Predicting {{Outcome}} after {{Traumatic Brain Injury}}: {{Development}} and {{International Validation}} of {{Prognostic Scores Based}} on {{Admission Characteristics}}},
  shorttitle = {Predicting {{Outcome}} after {{Traumatic Brain Injury}}},
  author = {Steyerberg, Ewout W. and Mushkudiani, Nino and Perel, Pablo and Butcher, Isabella and Lu, Juan and McHugh, Gillian S. and Murray, Gordon D. and Marmarou, Anthony and Roberts, Ian and Habbema, J. Dik F. and Maas, Andrew I. R.},
  year = {2008},
  month = aug,
  journal = {PLOS Medicine},
  volume = {5},
  number = {8},
  pages = {e165},
  publisher = {{Public Library of Science}},
  issn = {1549-1676},
  doi = {10.1371/journal.pmed.0050165},
  abstract = {Background Traumatic brain injury (TBI) is a leading cause of death and disability. A reliable prediction of outcome on admission is of great clinical relevance. We aimed to develop prognostic models with readily available traditional and novel predictors. Methods and Findings Prospectively collected individual patient data were analyzed from 11 studies. We considered predictors available at admission in logistic regression models to predict mortality and unfavorable outcome according to the Glasgow Outcome Scale at 6 mo after injury. Prognostic models were developed in 8,509 patients with severe or moderate TBI, with cross-validation by omission of each of the 11 studies in turn. External validation was on 6,681 patients from the recent Medical Research Council Corticosteroid Randomisation after Significant Head Injury (MRC CRASH) trial. We found that the strongest predictors of outcome were age, motor score, pupillary reactivity, and CT characteristics, including the presence of traumatic subarachnoid hemorrhage. A prognostic model that combined age, motor score, and pupillary reactivity had an area under the receiver operating characteristic curve (AUC) between 0.66 and 0.84 at cross-validation. This performance could be improved (AUC increased by approximately 0.05) by considering CT characteristics, secondary insults (hypotension and hypoxia), and laboratory parameters (glucose and hemoglobin). External validation confirmed that the discriminative ability of the model was adequate (AUC 0.80). Outcomes were systematically worse than predicted, but less so in 1,588 patients who were from high-income countries in the CRASH trial. Conclusions Prognostic models using baseline characteristics provide adequate discrimination between patients with good and poor 6 mo outcomes after TBI, especially if CT and laboratory findings are considered in addition to traditional predictors. The model predictions may support clinical practice and research, including the design and analysis of randomized controlled trials.},
  langid = {english},
  keywords = {Computed axial tomography,Glucose,Head injury,Hypotension,Hypoxia,Motor reactions,Randomized controlled trials,Traumatic brain injury},
  file = {C\:\\Users\\4216318\\Zotero\\storage\\NSIMDSK3\\Steyerberg et al. - 2008 - Predicting Outcome after Traumatic Brain Injury D.pdf;C\:\\Users\\4216318\\Zotero\\storage\\KVF2FSZU\\article.html}
}

@article{taljaardImputationStrategiesMissing2008,
  title = {Imputation {{Strategies}} for {{Missing Continuous Outcomes}} in {{Cluster Randomized Trials}}},
  author = {Taljaard, Monica and Donner, Allan and Klar, Neil},
  year = {2008},
  journal = {Biometrical Journal},
  volume = {50},
  number = {3},
  pages = {329--345},
  issn = {1521-4036},
  doi = {10.1002/bimj.200710423},
  abstract = {In cluster randomized trials, intact social units such as schools, worksites or medical practices \textendash{} rather than individuals themselves \textendash{} are randomly allocated to intervention and control conditions, while the outcomes of interest are then observed on individuals within each cluster. Such trials are becoming increasingly common in the fields of health promotion and health services research. Attrition is a common occurrence in randomized trials, and a standard approach for dealing with the resulting missing values is imputation. We consider imputation strategies for missing continuous outcomes, focusing on trials with a completely randomized design in which fixed cohorts from each cluster are enrolled prior to random assignment. We compare five different imputation strategies with respect to Type I and Type II error rates of the adjusted two-sample t -test for the intervention effect. Cluster mean imputation is compared with multiple imputation, using either within-cluster data or data pooled across clusters in each intervention group. In the case of pooling across clusters, we distinguish between standard multiple imputation procedures which do not account for intracluster correlation and a specialized procedure which does account for intracluster correlation but is not yet available in standard statistical software packages. A simulation study is used to evaluate the influence of cluster size, number of clusters, degree of intracluster correlation, and variability among cluster follow-up rates. We show that cluster mean imputation yields valid inferences and given its simplicity, may be an attractive option in some large community intervention trials which are subject to individual-level attrition only; however, it may yield less powerful inferences than alternative procedures which pool across clusters especially when the cluster sizes are small and cluster follow-up rates are highly variable. When pooling across clusters, the imputation procedure should generally take intracluster correlation into account to obtain valid inferences; however, as long as the intracluster correlation coefficient is small, we show that standard multiple imputation procedures may yield acceptable type I error rates; moreover, these procedures may yield more powerful inferences than a specialized procedure, especially when the number of available clusters is small. Within-cluster multiple imputation is shown to be the least powerful among the procedures considered. (\textcopyright{} 2008 WILEY-VCH Verlag GmbH \& Co. KGaA, Weinheim)},
  langid = {english},
  keywords = {Adjusted two-sample t -test,Attrition,Community intervention trial,Intracluster correlation,Mean imputation,Multiple imputation},
  file = {C\:\\Users\\4216318\\Zotero\\storage\\SQWPKYQ9\\Taljaard et al. - 2008 - Imputation Strategies for Missing Continuous Outco.pdf;C\:\\Users\\4216318\\Zotero\\storage\\VA3M5UWH\\bimj.html}
}

@article{yuce08,
  title = {Multiple Imputation Inference for Multivariate Multilevel Continuous Data with Ignorable Non-Response},
  author = {Yucel, Recai M},
  year = {2008},
  month = jul,
  journal = {Philosophical Transactions of the Royal Society A: Mathematical, Physical and Engineering Sciences},
  volume = {366},
  number = {1874},
  pages = {2389--2403},
  publisher = {{Royal Society}},
  doi = {10.1098/rsta.2008.0038},
  abstract = {Methods specifically targeting missing values in a wide spectrum of statistical analyses are now part of serious statistical thinking due to many advances in computational statistics and increased awareness among sophisticated consumers of statistics. Despite many advances in both theory and applied methods for missing data, missing-data methods in multilevel applications lack equal development. In this paper, I consider a popular inferential tool via multiple imputation in multilevel applications with missing values. I specifically consider missing values occurring arbitrarily at any level of observational units. I use Bayesian arguments for drawing multiple imputations from the underlying (posterior) predictive distribution of missing data. Multivariate extensions of well-known mixed-effects models form the basis for simulating the posterior predictive distribution, hence creating the multiple imputations. The discussion of these topics is demonstrated in an application assessing correlates to unmet need for mental health care among children with special health care needs.},
  keywords = {complex sample surveys,imputation,item non-response,linear mixed-effects models,longitudinal designs,missing data},
  file = {C\:\\Users\\4216318\\Zotero\\storage\\56HQ8ID9\\Yucel - 2008 - Multiple imputation inference for multivariate mul.pdf}
}

@article{yucelRandomcovariancesMixedeffectsModels2011,
  title = {Random-Covariances and Mixed-Effects Models for Imputing Multivariate Multilevel Continuous Data},
  author = {Yucel, Recai M.},
  year = {2011},
  month = aug,
  journal = {Statistical modelling},
  volume = {11},
  number = {4},
  pages = {351--370},
  issn = {1471-082X},
  doi = {10.1177/1471082X1001100404},
  abstract = {Principled techniques for incomplete-data problems are increasingly part of mainstream statistical practice. Among many proposed techniques so far, inference by multiple imputation (MI) has emerged as one of the most popular. While many strategies leading to inference by MI are available in cross-sectional settings, the same richness does not exist in multilevel applications. The limited methods available for multilevel applications rely on the multivariate adaptations of mixed-effects models. This approach preserves the mean structure across clusters and incorporates distinct variance components into the imputation process. In this paper, I add to these methods by considering a random covariance structure and develop computational algorithms. The attraction of this new imputation modeling strategy is to correctly reflect the mean and variance structure of the joint distribution of the data, and allow the covariances differ across the clusters. Using Markov Chain Monte Carlo techniques, a predictive distribution of missing data given observed data is simulated leading to creation of multiple imputations. To circumvent the large sample size requirement to support independent covariance estimates for the level-1 error term, I consider distributional impositions mimicking random-effects distributions assigned a priori. These techniques are illustrated in an example exploring relationships between victimization and individual and contextual level factors that raise the risk of violent crime.},
  pmcid = {PMC3263314},
  pmid = {22271079},
  file = {C\:\\Users\\4216318\\Zotero\\storage\\36AC658Z\\Yucel - 2011 - Random-covariances and mixed-effects models for im.pdf}
}
